{"cells":[{"cell_type":"markdown","metadata":{"id":"MyeRMcazzy7_"},"source":["Laura is running this code locally, please talk to me before modifying\n"]},{"cell_type":"markdown","metadata":{"id":"NRyIoDn0RPjq"},"source":["# Framework"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16005,"status":"ok","timestamp":1702624535202,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"PsM77476zhxN","outputId":"4bb16231-929b-48d9-ac90-3d0d83bebad9"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13613,"status":"ok","timestamp":1702626260585,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"PXKbm7_4y45O","outputId":"bd5b913e-971c-4bf7-b2df-4928d974d7f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting emoji\n","  Downloading emoji-2.9.0-py2.py3-none-any.whl.metadata (5.3 kB)\n","Downloading emoji-2.9.0-py2.py3-none-any.whl (397 kB)\n","   -------------------------------------- 397.5/397.5 kB 266.5 kB/s eta 0:00:00\n","Installing collected packages: emoji\n","Successfully installed emoji-2.9.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install emoji"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10905,"status":"ok","timestamp":1702581907676,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"PCrVYQV2xZop","outputId":"05816b8f-8182-4bb0-ab39-9befe7391f3d"},"outputs":[],"source":["#%pip install git+https://github.com/phatpiglet/autocorrect.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7589,"status":"ok","timestamp":1702582107760,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"R2MwfZFvzRO3","outputId":"b5dc75e5-5151-40e5-aed0-94f14708ac84"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting textblob\n","  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n","     ------------------------------------ 636.8/636.8 kB 221.5 kB/s eta 0:00:00\n","Collecting nltk>=3.1 (from textblob)\n","  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n","     ---------------------------------------- 1.5/1.5 MB 214.8 kB/s eta 0:00:00\n","Requirement already satisfied: click in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from nltk>=3.1->textblob) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from nltk>=3.1->textblob) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from nltk>=3.1->textblob) (2023.10.3)\n","Requirement already satisfied: tqdm in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from nltk>=3.1->textblob) (4.66.1)\n","Requirement already satisfied: colorama in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n","Installing collected packages: nltk, textblob\n","Successfully installed nltk-3.8.1 textblob-0.17.1\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: The script nltk.exe is installed in 'C:\\Users\\PabloFabianFaundezGa\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"]}],"source":["%pip install textblob"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#%pip install scikit-learn"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting datasets\n","  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (1.23.5)\n","Collecting pyarrow>=8.0.0 (from datasets)\n","  Downloading pyarrow-14.0.2-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n","Collecting pyarrow-hotfix (from datasets)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: pandas in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (1.5.2)\n","Requirement already satisfied: requests>=2.19.0 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n","Collecting aiohttp (from datasets)\n","  Downloading aiohttp-3.9.1-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n","Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.19.4)\n","Requirement already satisfied: packaging in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (23.1.0)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n","  Downloading multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n","  Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n","Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n","  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n","Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: filelock in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.18.0->datasets) (4.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: colorama in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n","Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: six>=1.5 in c:\\users\\pablofabianfaundezga\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n","   ---------------------------------------- 521.2/521.2 kB 3.0 MB/s eta 0:00:00\n","Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","   ---------------------------------------- 115.3/115.3 kB 3.4 MB/s eta 0:00:00\n","Downloading aiohttp-3.9.1-cp311-cp311-win_amd64.whl (364 kB)\n","   ---------------------------------------- 364.8/364.8 kB 1.7 MB/s eta 0:00:00\n","Downloading pyarrow-14.0.2-cp311-cp311-win_amd64.whl (24.6 MB)\n","   ---------------------------------------- 24.6/24.6 MB 2.4 MB/s eta 0:00:00\n","Downloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n","   ---------------------------------------- 135.4/135.4 kB ? eta 0:00:00\n","Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n","Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n","   ---------------------------------------- 50.5/50.5 kB 2.5 MB/s eta 0:00:00\n","Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n","   ---------------------------------------- 76.7/76.7 kB 4.4 MB/s eta 0:00:00\n","Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, frozenlist, dill, yarl, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 datasets-2.15.0 dill-0.3.7 frozenlist-1.4.1 multidict-6.0.4 multiprocess-0.70.15 pyarrow-14.0.2 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\PabloFabianFaundezGa\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"]}],"source":["%pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#%pip install transformers"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702626260585,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"0BWM8quQQhxH"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW, DistilBertConfig\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import pandas as pd\n","import numpy as np\n","from textblob import TextBlob\n","import re\n","import emoji\n","import matplotlib.pyplot as plt\n","from datasets import load_metric\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import make_scorer, accuracy_score, precision_score, f1_score, recall_score\n","from sklearn.pipeline import Pipeline\n","from tqdm import tqdm\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.model_selection import ParameterGrid\n","from torch.nn.utils.rnn import pad_sequence"]},{"cell_type":"markdown","metadata":{"id":"lpfLNhnvzc4K"},"source":["# Data Exploration"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":965,"status":"ok","timestamp":1702626268476,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"NRV1tlwzqGL_","outputId":"bf9acf72-f640-4eb4-9526-d7c2a25fd361"},"outputs":[{"name":"stdout","output_type":"stream","text":["   id  label                                              tweet\n","0   1      0   @user when a father is dysfunctional and is s...\n","1   2      0  @user @user thanks for #lyft credit i can't us...\n","2   3      0                                bihday your majesty\n","3   4      0  #model   i love u take with u all the time in ...\n","4   5      0             factsguide: society now    #motivation\n"]}],"source":["# Load dataset\n","hatespeech_train = pd.read_csv('hatespeech_train.csv')\n","\n","# Display the first few rows of the dataset\n","print(hatespeech_train.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":290,"status":"ok","timestamp":1702626270411,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"N0RRhuOJ0S6P","outputId":"61bec34e-5a5b-4a8c-80a8-12c0ccf042d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["count       31962.000000\n","mean            0.070146\n","std             0.255397\n","min             0.000000\n","25%             0.000000\n","50%             0.000000\n","75%             0.000000\n","max             1.000000\n","median          0.000000\n","std_dev         0.255397\n","skewness        3.366381\n","Name: label, dtype: float64\n"]}],"source":["# Check the exact name of your label column\n","label_column_name = 'label'  # Replace with the actual name\n","\n","# Calculate EDA metrics on Label\n","label_stats = hatespeech_train[label_column_name].describe()\n","\n","# Calculate additional metrics\n","label_stats['mean'] = hatespeech_train[label_column_name].mean()\n","label_stats['median'] = hatespeech_train[label_column_name].median()\n","label_stats['std_dev'] = hatespeech_train[label_column_name].std()\n","label_stats['skewness'] = hatespeech_train[label_column_name].skew()\n","\n","# Display the calculated metrics\n","print(label_stats)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":1237,"status":"ok","timestamp":1702626275459,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"1aQ9HrNj0VgX","outputId":"59b1cd12-1b52-42ac-d18a-de19957e9e36"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Plot label\n","hatespeech_train[label_column_name].value_counts().plot(kind='bar', title='Label Distribution')\n","plt.xlabel('Label')\n","plt.ylabel('Count')\n","plt.xticks([0, 1], ['Not Hate Speech (0)', 'Hate Speech (1)'], rotation=0)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"l1MKGJcl3Vu8"},"source":["# Data Pre-Processing"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'file_path' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Dataset Definition\u001b[39;00m\n\u001b[0;32m      2\u001b[0m twits_25k_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhatespeech_train.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m twits_25k \u001b[39m=\u001b[39m dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_path)\n","\u001b[1;31mNameError\u001b[0m: name 'file_path' is not defined"]}],"source":["#Dataset Definition\n","twits_25k_path = '25k_dataset.csv'\n","twits_32k_path = 'hatespeech_train.csv'\n","twits_150_path = \n","\n","twits_25k = pd.read_csv(twits_25k_path)\n","twits_32k = pd.read_csv(twits_32k_path)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\n\u001b[0;32m     23\u001b[0m \u001b[39m# Uso de la función con tu ruta de archivo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m hatespeech_train_preprocessed \u001b[39m=\u001b[39m preprocess_dataset(\u001b[39m'\u001b[39;49m\u001b[39mhatespeech_train.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     26\u001b[0m \u001b[39m# Muestra las primeras filas del DataFrame resultante\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(hatespeech_train_preprocessed\u001b[39m.\u001b[39mhead())\n","Cell \u001b[1;32mIn[14], line 14\u001b[0m, in \u001b[0;36mpreprocess_dataset\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mreplace(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwww\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Use TextBlob for spelling correction\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39;49m\u001b[39mtweet\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mstr\u001b[39;49m(TextBlob(x)\u001b[39m.\u001b[39;49mcorrect()))\n\u001b[0;32m     15\u001b[0m \u001b[39m# Convert emojis to text and keep sentiment\u001b[39;00m\n\u001b[0;32m     16\u001b[0m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: emoji\u001b[39m.\u001b[39mdemojize(x))\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n","Cell \u001b[1;32mIn[14], line 14\u001b[0m, in \u001b[0;36mpreprocess_dataset.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     12\u001b[0m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mreplace(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwww\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Use TextBlob for spelling correction\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(TextBlob(x)\u001b[39m.\u001b[39;49mcorrect()))\n\u001b[0;32m     15\u001b[0m \u001b[39m# Convert emojis to text and keep sentiment\u001b[39;00m\n\u001b[0;32m     16\u001b[0m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: emoji\u001b[39m.\u001b[39mdemojize(x))\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\blob.py:609\u001b[0m, in \u001b[0;36mBaseBlob.correct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    607\u001b[0m tokens \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mtokenize\u001b[39m.\u001b[39mregexp_tokenize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+|[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    608\u001b[0m corrected \u001b[39m=\u001b[39m (Word(w)\u001b[39m.\u001b[39mcorrect() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens)\n\u001b[1;32m--> 609\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(corrected)\n\u001b[0;32m    610\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(ret)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\blob.py:608\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[39m# regex matches: word or punctuation or whitespace\u001b[39;00m\n\u001b[0;32m    607\u001b[0m tokens \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mtokenize\u001b[39m.\u001b[39mregexp_tokenize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+|[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 608\u001b[0m corrected \u001b[39m=\u001b[39m (Word(w)\u001b[39m.\u001b[39;49mcorrect() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens)\n\u001b[0;32m    609\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(corrected)\n\u001b[0;32m    610\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(ret)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\blob.py:142\u001b[0m, in \u001b[0;36mWord.correct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcorrect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    137\u001b[0m     \u001b[39m'''Correct the spelling of the word. Returns the word with the highest\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m    confidence using the spelling corrector.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[39m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m Word(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspellcheck()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\blob.py:134\u001b[0m, in \u001b[0;36mWord.spellcheck\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspellcheck\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    126\u001b[0m     \u001b[39m'''Return a list of (word, confidence) tuples of spelling corrections.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[39m    Based on: Peter Norvig, \"How to Write a Spelling Corrector\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m suggest(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstring)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\en\\__init__.py:123\u001b[0m, in \u001b[0;36msuggest\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msuggest\u001b[39m(w):\n\u001b[0;32m    121\u001b[0m     \u001b[39m\"\"\" Returns a list of (word, confidence)-tuples of spelling corrections.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m spelling\u001b[39m.\u001b[39;49msuggest(w)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:1399\u001b[0m, in \u001b[0;36mSpelling.suggest\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[39mif\u001b[39;00m w\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39misdigit():\n\u001b[0;32m   1396\u001b[0m     \u001b[39mreturn\u001b[39;00m [(w, \u001b[39m1.0\u001b[39m)] \u001b[39m# 1.5\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m candidates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known([w]) \\\n\u001b[0;32m   1398\u001b[0m           \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(w)) \\\n\u001b[1;32m-> 1399\u001b[0m           \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_edit2(w)) \\\n\u001b[0;32m   1400\u001b[0m           \u001b[39mor\u001b[39;00m [w]\n\u001b[0;32m   1401\u001b[0m candidates \u001b[39m=\u001b[39m [(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(c, \u001b[39m0.0\u001b[39m), c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m candidates]\n\u001b[0;32m   1402\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39msum\u001b[39m(p \u001b[39mfor\u001b[39;00m p, word \u001b[39min\u001b[39;00m candidates) \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:1376\u001b[0m, in \u001b[0;36mSpelling._edit2\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39m\"\"\" Returns a set of words with edit distance 2 from the given word\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[39m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[39m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[1;32m-> 1376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39m(e2 \u001b[39mfor\u001b[39;00m e1 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(w) \u001b[39mfor\u001b[39;00m e2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(e1) \u001b[39mif\u001b[39;00m e2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:1376\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39m\"\"\" Returns a set of words with edit distance 2 from the given word\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[39m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[39m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[1;32m-> 1376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39m(e2 \u001b[39mfor\u001b[39;00m e1 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(w) \u001b[39mfor\u001b[39;00m e2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(e1) \u001b[39mif\u001b[39;00m e2 \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:96\u001b[0m, in \u001b[0;36mlazydict.__contains__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__contains__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy(\u001b[39m\"\u001b[39;49m\u001b[39m__contains__\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:87\u001b[0m, in \u001b[0;36mlazydict._lazy\u001b[1;34m(self, method, *args)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload()\n\u001b[0;32m     86\u001b[0m     \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, method, types\u001b[39m.\u001b[39mMethodType(\u001b[39mgetattr\u001b[39m(\u001b[39mdict\u001b[39m, method), \u001b[39mself\u001b[39m))\n\u001b[1;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mdict\u001b[39m, method)(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import pandas as pd\n","from textblob import TextBlob\n","import emoji\n","import re\n","\n","def preprocess_dataset(file_path):\n","    # Load dataset\n","    dataset = pd.read_csv(file_path)\n","    # Change text to lowercase\n","    dataset['tweet'] = dataset['tweet'].str.lower()\n","    # Eliminate URLs\n","    dataset['tweet'] = dataset['tweet'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n","    # Use TextBlob for spelling correction\n","    dataset['tweet'] = dataset['tweet'].apply(lambda x: str(TextBlob(x).correct()))\n","    # Convert emojis to text and keep sentiment\n","    dataset['tweet'] = dataset['tweet'].apply(lambda x: emoji.demojize(x))\n","    # Keep hashtags\n","    dataset['tweet'] = dataset['tweet'].apply(lambda x: re.sub(r'#', '', x))\n","    # Eliminate @mentions\n","    dataset['tweet'] = dataset['tweet'].replace(r'@\\S+', '', regex=True)\n","    return dataset\n","\n","# Uso de la función con tu ruta de archivo\n","hatespeech_train_preprocessed = preprocess_dataset('hatespeech_train.csv')\n","\n","# Muestra las primeras filas del DataFrame resultante\n","print(hatespeech_train_preprocessed.head())\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   id  label                                              tweet\n","0   1      0   @user when a father is dysfunctional and is s...\n","1   2      0  @user @user thanks for #lyft credit i can't us...\n","2   3      0                                bihday your majesty\n","3   4      0  #model   i love u take with u all the time in ...\n","4   5      0             factsguide: society now    #motivation\n"]}],"source":["# Load dataset\n","hatespeech_train = pd.read_csv('hatespeech_train.csv')\n","\n","# Display the first few rows of the dataset\n","print(hatespeech_train.head())"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1702626424714,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"XJFAzFmE3VQN"},"outputs":[],"source":["# Change text to lowercase\n","hatespeech_train['tweet'] = hatespeech_train['tweet'].str.lower()\n","\n","# Eliminate URLs\n","hatespeech_train['tweet'] = hatespeech_train['tweet'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Ug7mObHZb2uu"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Use TextBlob for spelling correction\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hatespeech_train[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m hatespeech_train[\u001b[39m'\u001b[39;49m\u001b[39mtweet\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mstr\u001b[39;49m(TextBlob(x)\u001b[39m.\u001b[39;49mcorrect()))\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n","Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Use TextBlob for spelling correction\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hatespeech_train[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m hatespeech_train[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(TextBlob(x)\u001b[39m.\u001b[39;49mcorrect()))\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\blob.py:609\u001b[0m, in \u001b[0;36mBaseBlob.correct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    607\u001b[0m tokens \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mtokenize\u001b[39m.\u001b[39mregexp_tokenize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+|[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    608\u001b[0m corrected \u001b[39m=\u001b[39m (Word(w)\u001b[39m.\u001b[39mcorrect() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens)\n\u001b[1;32m--> 609\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(corrected)\n\u001b[0;32m    610\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(ret)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\blob.py:608\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[39m# regex matches: word or punctuation or whitespace\u001b[39;00m\n\u001b[0;32m    607\u001b[0m tokens \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mtokenize\u001b[39m.\u001b[39mregexp_tokenize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+|[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 608\u001b[0m corrected \u001b[39m=\u001b[39m (Word(w)\u001b[39m.\u001b[39;49mcorrect() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens)\n\u001b[0;32m    609\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(corrected)\n\u001b[0;32m    610\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(ret)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\blob.py:142\u001b[0m, in \u001b[0;36mWord.correct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcorrect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    137\u001b[0m     \u001b[39m'''Correct the spelling of the word. Returns the word with the highest\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m    confidence using the spelling corrector.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[39m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m Word(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspellcheck()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\blob.py:134\u001b[0m, in \u001b[0;36mWord.spellcheck\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspellcheck\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    126\u001b[0m     \u001b[39m'''Return a list of (word, confidence) tuples of spelling corrections.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[39m    Based on: Peter Norvig, \"How to Write a Spelling Corrector\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m suggest(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstring)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\en\\__init__.py:123\u001b[0m, in \u001b[0;36msuggest\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msuggest\u001b[39m(w):\n\u001b[0;32m    121\u001b[0m     \u001b[39m\"\"\" Returns a list of (word, confidence)-tuples of spelling corrections.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m spelling\u001b[39m.\u001b[39;49msuggest(w)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:1399\u001b[0m, in \u001b[0;36mSpelling.suggest\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[39mif\u001b[39;00m w\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39misdigit():\n\u001b[0;32m   1396\u001b[0m     \u001b[39mreturn\u001b[39;00m [(w, \u001b[39m1.0\u001b[39m)] \u001b[39m# 1.5\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m candidates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known([w]) \\\n\u001b[0;32m   1398\u001b[0m           \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(w)) \\\n\u001b[1;32m-> 1399\u001b[0m           \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_edit2(w)) \\\n\u001b[0;32m   1400\u001b[0m           \u001b[39mor\u001b[39;00m [w]\n\u001b[0;32m   1401\u001b[0m candidates \u001b[39m=\u001b[39m [(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(c, \u001b[39m0.0\u001b[39m), c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m candidates]\n\u001b[0;32m   1402\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39msum\u001b[39m(p \u001b[39mfor\u001b[39;00m p, word \u001b[39min\u001b[39;00m candidates) \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:1376\u001b[0m, in \u001b[0;36mSpelling._edit2\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39m\"\"\" Returns a set of words with edit distance 2 from the given word\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[39m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[39m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[1;32m-> 1376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39m(e2 \u001b[39mfor\u001b[39;00m e1 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(w) \u001b[39mfor\u001b[39;00m e2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(e1) \u001b[39mif\u001b[39;00m e2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:1376\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39m\"\"\" Returns a set of words with edit distance 2 from the given word\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[39m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[39m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[1;32m-> 1376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39m(e2 \u001b[39mfor\u001b[39;00m e1 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(w) \u001b[39mfor\u001b[39;00m e2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(e1) \u001b[39mif\u001b[39;00m e2 \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:96\u001b[0m, in \u001b[0;36mlazydict.__contains__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__contains__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy(\u001b[39m\"\u001b[39;49m\u001b[39m__contains__\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\textblob\\_text.py:87\u001b[0m, in \u001b[0;36mlazydict._lazy\u001b[1;34m(self, method, *args)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload()\n\u001b[0;32m     86\u001b[0m     \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, method, types\u001b[39m.\u001b[39mMethodType(\u001b[39mgetattr\u001b[39m(\u001b[39mdict\u001b[39m, method), \u001b[39mself\u001b[39m))\n\u001b[1;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mdict\u001b[39m, method)(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Use TextBlob for spelling correction\n","hatespeech_train['tweet'] = hatespeech_train['tweet'].apply(lambda x: str(TextBlob(x).correct()))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1702626698517,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"DjftRlGjb4ux"},"outputs":[],"source":["# Convert emojis to text and keep sentiment\n","hatespeech_train['tweet'] = hatespeech_train['tweet'].apply(lambda x: emoji.demojize(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1702626698517,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"A1F3y0cbb8pX"},"outputs":[],"source":["# Keep hashtags\n","hatespeech_train['tweet'] = hatespeech_train['tweet'].apply(lambda x: re.sub(r'#', '', x))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1702626698517,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"WzlC2rb9b-RR"},"outputs":[],"source":["# Eliminate @mentions\n","hatespeech_train['tweet'] = hatespeech_train['tweet'].replace(r'@\\S+', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hatespeech_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the prepared DataFrame to a CSV file\n","hatespeech_train.to_csv('/Users/lauraguinandrodriguez/Desktop/Hate Speech/prepared_hatespeech_train.csv', index=False)\n","\n","print(f\"Prepared data saved to {'/Users/lauraguinandrodriguez/Desktop/Hate Speech/prepared_hatespeech_train.csv'}\")"]},{"cell_type":"markdown","metadata":{"id":"roPABhPRcbuU"},"source":["Train and Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1702583133089,"user":{"displayName":"Laura Guinand","userId":"10698960873191413459"},"user_tz":-60},"id":"lKl7Nlmo3LSG","outputId":"2e5617c1-f5a4-4513-cbb0-bb27ae58de58"},"outputs":[],"source":["# Split the dataset into train (80%) and test (20%)\n","train_df, test_df = train_test_split(hatespeech_train, test_size=0.2, random_state=42)\n","\n","# Display the first few rows of the preprocessed dataset\n","print(train_df.head())\n","print(test_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save train and test datasets to CSV files\n","train_df.to_csv('train_dataset.csv', index=False)\n","test_df.to_csv('test_dataset.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# DistilBERT Pre-trained Model"]},{"cell_type":"markdown","metadata":{},"source":["## Load Train and Test Datasets"]},{"cell_type":"markdown","metadata":{},"source":["Issues with tokenization made in the data preparation so they were implemented below in the cell that runs the model. \n","To reduce time, droped Tokens column when calling the current saved csv and re-ran the tokenization and label encoding below. "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      id  label                                              tweet\n","0  12111      1     because i've been paying attention for the ...\n","1  14082      0    raft building at salford quays as pa of the ...\n","2   1830      0  friday ðð» gdegblog friday selfie   beard...\n","3   2770      0                        fashion it is a true   fact\n","4  31819      0  so   to share the simple, elegant businesscard...\n"]}],"source":["# Load dataset\n","hatespeech_train = pd.read_csv('/Users/lauraguinandrodriguez/Desktop/Hate Speech/train_dataset.csv')\n","\n","# Drop the 'Tokens' column\n","hatespeech_train = hatespeech_train.drop(columns=['Tokens'])\n","\n","# Display the first few rows of the modified dataset\n","print(hatespeech_train.head())"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      id  label                                              tweet\n","0  12228      0    âmy mom says my smile is captivatingâ¦ i ...\n","1  14710      0  in 3 days i will be meeting my sis-n-law, coun...\n","2  19320      0  hating the conservative homophobes using this ...\n","3   4309      0  awee if this doesn't  scream   friday acewells...\n","4  24056      0   fathersday  fatherã¢ââs day god! ãâ« tony ...\n"]}],"source":["# Load dataset\n","hatespeech_test = pd.read_csv('/Users/lauraguinandrodriguez/Desktop/Hate Speech/test_dataset.csv')\n","\n","# Drop the 'Tokens' column\n","hatespeech_test = hatespeech_test.drop(columns=['Tokens'])\n","\n","# Display the first few rows of the modified dataset\n","print(hatespeech_test.head())"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenization, Label encoding, Hyperparameter Tunning, GridSearch, Evaluation"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/8 [00:00<?, ?it/s]Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/3: 100%|██████████| 1599/1599 [26:55<00:00,  1.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3, Average Training Loss: 0.14391764020605516\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/3: 100%|██████████| 1599/1599 [26:12<00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/3, Average Training Loss: 0.0787716812729076\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/3: 100%|██████████| 1599/1599 [26:14<00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/3, Average Training Loss: 0.0424393708361173\n"]},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 400/400 [02:18<00:00,  2.89it/s]\n"," 12%|█▎        | 1/8 [1:21:42<9:32:00, 4902.89s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/3, Evaluation Metrics: {'accuracy': 0.9691850461442202, 'precision': 0.9768793735593353, 'recall': 0.9691850461442202, 'f1': 0.9694063770068169}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/3: 100%|██████████| 1599/1599 [26:25<00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3, Average Training Loss: 0.14040649102194372\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/3: 100%|██████████| 1599/1599 [26:25<00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/3, Average Training Loss: 0.06679706694627428\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/3: 100%|██████████| 1599/1599 [27:02<00:00,  1.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/3, Average Training Loss: 0.02764650294274639\n"]},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 400/400 [02:18<00:00,  2.88it/s]\n"," 25%|██▌       | 2/8 [2:43:56<8:12:05, 4920.99s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/3, Evaluation Metrics: {'accuracy': 0.9679336774597216, 'precision': 0.973555146167769, 'recall': 0.9679336774597216, 'f1': 0.9640664405599851}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/7: 100%|██████████| 1599/1599 [28:07<00:00,  1.06s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/7, Average Training Loss: 0.1476514573419249\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/7: 100%|██████████| 1599/1599 [27:51<00:00,  1.05s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/7, Average Training Loss: 0.08161305644904136\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/7: 100%|██████████| 1599/1599 [26:22<00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/7, Average Training Loss: 0.043992744816168376\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/7: 100%|██████████| 1599/1599 [26:25<00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/7, Average Training Loss: 0.0236165699850942\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/7: 100%|██████████| 1599/1599 [1:08:41<00:00,  2.58s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/7, Average Training Loss: 0.012458787496689525\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/7: 100%|██████████| 1599/1599 [28:32<00:00,  1.07s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/7, Average Training Loss: 0.007370539780636019\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/7: 100%|██████████| 1599/1599 [27:12<00:00,  1.02s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/7, Average Training Loss: 0.00764018472882054\n"]},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 400/400 [02:19<00:00,  2.87it/s]\n"," 38%|███▊      | 3/8 [6:39:29<12:40:36, 9127.38s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/7, Evaluation Metrics: {'accuracy': 0.9691850461442202, 'precision': 0.9776568021112829, 'recall': 0.9691850461442202, 'f1': 0.9694383291419922}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/7: 100%|██████████| 1599/1599 [26:28<00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/7, Average Training Loss: 0.1338973154354342\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/7: 100%|██████████| 1599/1599 [26:30<00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/7, Average Training Loss: 0.06127012667359447\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/7: 100%|██████████| 1599/1599 [26:39<00:00,  1.00s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/7, Average Training Loss: 0.02782008293388543\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/7: 100%|██████████| 1599/1599 [26:52<00:00,  1.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/7, Average Training Loss: 0.014165323538778748\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/7: 100%|██████████| 1599/1599 [26:54<00:00,  1.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/7, Average Training Loss: 0.010536849357165652\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/7: 100%|██████████| 1599/1599 [27:49<00:00,  1.04s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/7, Average Training Loss: 0.006514112767140498\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/7: 100%|██████████| 1599/1599 [27:54<00:00,  1.05s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/7, Average Training Loss: 0.006812969860726557\n"]},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 400/400 [02:20<00:00,  2.84it/s]\n"," 50%|█████     | 4/8 [9:50:59<11:10:40, 10060.19s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/7, Evaluation Metrics: {'accuracy': 0.9685593618019709, 'precision': 0.9783348345173772, 'recall': 0.9685593618019709, 'f1': 0.9700331369511214}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/3: 100%|██████████| 1599/1599 [29:42<00:00,  1.11s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3, Average Training Loss: 0.14290864139724246\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/3: 100%|██████████| 1599/1599 [29:31<00:00,  1.11s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/3, Average Training Loss: 0.0776936314404366\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/3: 100%|██████████| 1599/1599 [25:31<00:00,  1.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/3, Average Training Loss: 0.04238936470328172\n"]},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 400/400 [02:21<00:00,  2.83it/s]\n"," 62%|██████▎   | 5/8 [11:18:07<6:55:52, 8317.49s/it] "]},{"name":"stdout","output_type":"stream","text":["Epoch 3/3, Evaluation Metrics: {'accuracy': 0.9690286250586579, 'precision': 0.9754005353841103, 'recall': 0.9690286250586579, 'f1': 0.9653698519512862}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/3: 100%|██████████| 1599/1599 [43:50<00:00,  1.65s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3, Average Training Loss: 0.14052517220791164\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/3: 100%|██████████| 1599/1599 [25:51<00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/3, Average Training Loss: 0.06448832185323533\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/3: 100%|██████████| 1599/1599 [25:56<00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/3, Average Training Loss: 0.02316541311177766\n"]},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"," 75%|███████▌  | 6/8 [12:56:02<4:09:34, 7487.20s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/3, Evaluation Metrics: {'accuracy': 0.9679336774597216, 'precision': 0.9766023993733982, 'recall': 0.9679336774597216, 'f1': 0.9673973486000167}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/7: 100%|██████████| 1599/1599 [25:48<00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/7, Average Training Loss: 0.16305473887404104\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/7: 100%|██████████| 1599/1599 [25:56<00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/7, Average Training Loss: 0.0816807861097991\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/7: 100%|██████████| 1599/1599 [35:49<00:00,  1.34s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/7, Average Training Loss: 0.04381592309953799\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/7: 100%|██████████| 1599/1599 [25:57<00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/7, Average Training Loss: 0.0210095121430454\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/7: 100%|██████████| 1599/1599 [25:55<00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/7, Average Training Loss: 0.011816480597030832\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/7: 100%|██████████| 1599/1599 [26:12<00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/7, Average Training Loss: 0.009340948422958205\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/7: 100%|██████████| 1599/1599 [5:48:42<00:00, 13.08s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/7, Average Training Loss: 0.0062656723292808915\n"]},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 400/400 [47:10<00:00,  7.08s/it]\n"," 88%|████████▊ | 7/8 [22:17:36<4:27:34, 16054.82s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/7, Evaluation Metrics: {'accuracy': 0.9702799937431565, 'precision': 0.9772128140382476, 'recall': 0.9702799937431565, 'f1': 0.9690616670648511}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/7: 100%|██████████| 1599/1599 [2:40:17<00:00,  6.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/7, Average Training Loss: 0.1340365563650348\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/7: 100%|██████████| 1599/1599 [26:03<00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/7, Average Training Loss: 0.06425283414438315\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/7: 100%|██████████| 1599/1599 [1:45:38<00:00,  3.96s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/7, Average Training Loss: 0.029133605897556782\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/7: 100%|██████████| 1599/1599 [26:31<00:00,  1.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/7, Average Training Loss: 0.012352415365165324\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/7: 100%|██████████| 1599/1599 [28:29<00:00,  1.07s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/7, Average Training Loss: 0.007585932676598444\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/7: 100%|██████████| 1599/1599 [26:49<00:00,  1.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/7, Average Training Loss: 0.008467712952194464\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/7: 100%|██████████| 1599/1599 [35:13<00:00,  1.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/7, Average Training Loss: 0.006792528366086407\n"]},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 400/400 [02:14<00:00,  2.97it/s]\n","100%|██████████| 8/8 [29:08:56<00:00, 13117.06s/it]  "]},{"name":"stdout","output_type":"stream","text":["Epoch 7/7, Evaluation Metrics: {'accuracy': 0.9644924135773503, 'precision': 0.9690269419563174, 'recall': 0.9644924135773503, 'f1': 0.9546627118940005}\n","Best Hyperparameters: {'batch_size': 32, 'epochs': 7, 'learning_rate': 1e-05}\n","Best Accuracy: 0.9702799937431565\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Tokenization\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","hatespeech_train['Tokens'] = hatespeech_train['tweet'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n","hatespeech_test['Tokens'] = hatespeech_test['tweet'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n","\n","# Label Encoding\n","label_encoder = LabelEncoder()\n","hatespeech_train['label'] = label_encoder.fit_transform(hatespeech_train['label'])\n","hatespeech_test['label'] = label_encoder.transform(hatespeech_test['label'])\n","\n","# Padding sequences\n","token_tensors_train = [torch.tensor(token_ids) for token_ids in hatespeech_train['Tokens']]\n","token_tensors_test = [torch.tensor(token_ids) for token_ids in hatespeech_test['Tokens']]\n","\n","padded_token_tensors_train = pad_sequence(token_tensors_train, batch_first=True, padding_value=0)\n","padded_token_tensors_test = pad_sequence(token_tensors_test, batch_first=True, padding_value=0)\n","\n","# Create TensorDatasets\n","dataset_train = TensorDataset(padded_token_tensors_train, torch.tensor(hatespeech_train['label'].tolist()))\n","dataset_test = TensorDataset(padded_token_tensors_test, torch.tensor(hatespeech_test['label'].tolist()))\n","\n","# Hyperparameter Grid Search\n","param_grid = {\n","    'learning_rate': [1e-5, 3e-5],\n","    'epochs': [3, 7],\n","    'batch_size': [16, 32]\n","}\n","\n","best_accuracy = 0\n","best_hyperparameters = None\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# DataLoader instances for training and validation\n","train_dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n","validation_dataloader = DataLoader(dataset_test, batch_size=batch_size)\n","\n","# Loop through hyperparameter combinations\n","for params in tqdm(list(ParameterGrid(param_grid))):\n","    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased').to(device)\n","    optimizer = AdamW(model.parameters(), lr=params['learning_rate'])\n","\n","    # Training loop\n","    for epoch in range(params['epochs']):\n","        model.train()\n","        total_loss = 0\n","\n","        # Iterate over batches\n","        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{params['epochs']}\"):\n","            inputs, labels = batch\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(inputs, labels=labels)  # Specify labels during training\n","            loss = outputs.loss\n","\n","            # Backward pass and optimization\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        # Calculate average training loss for the epoch\n","        average_loss = total_loss / len(train_dataloader)\n","        print(f\"Epoch {epoch + 1}/{params['epochs']}, Average Training Loss: {average_loss}\")\n","\n","    # Evaluation (Move these lines outside the training loop)\n","    model.eval()\n","    with torch.no_grad():\n","        total_metrics = {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n","        total_samples = 0\n","\n","        for val_batch in tqdm(validation_dataloader, desc=f\"Evaluation\"):\n","            val_inputs, val_labels = val_batch\n","            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n","\n","            # Forward pass\n","            val_outputs = model(val_inputs)\n","            val_predictions = val_outputs.logits.argmax(dim=-1)\n","\n","            # Update metrics\n","            total_metrics['accuracy'] += accuracy_score(val_labels.cpu(), val_predictions.cpu()) * len(val_labels)\n","            total_metrics['precision'] += precision_score(val_labels.cpu(), val_predictions.cpu(), average='weighted', zero_division=1.0) * len(val_labels)\n","            total_metrics['recall'] += recall_score(val_labels.cpu(), val_predictions.cpu(), average='weighted', zero_division=1.0) * len(val_labels)\n","            total_metrics['f1'] += f1_score(val_labels.cpu(), val_predictions.cpu(), average='weighted', zero_division=1.0) * len(val_labels)\n","\n","            total_samples += len(val_labels)\n","\n","        # Calculate average metrics for the epoch\n","        average_metrics = {key: total_metrics[key] / total_samples for key in total_metrics}\n","        print(f\"Epoch {epoch + 1}/{params['epochs']}, Evaluation Metrics: {average_metrics}\")\n","\n","    # Check if current hyperparameters result in better accuracy\n","    if average_metrics['accuracy'] > best_accuracy:\n","        best_accuracy = average_metrics['accuracy']\n","        best_hyperparameters = params\n","\n","# Print the best hyperparameters and corresponding accuracy\n","print(\"Best Hyperparameters:\", best_hyperparameters)\n","print(\"Best Accuracy:\", best_accuracy)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.11.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"}}},"nbformat":4,"nbformat_minor":0}
